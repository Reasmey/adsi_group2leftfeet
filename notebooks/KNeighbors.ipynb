{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/hyperopt/hyperopt-sklearn.git\n",
      "  Cloning https://github.com/hyperopt/hyperopt-sklearn.git to /tmp/pip-req-build-6iolv73c\n",
      "  Running command git clone -q https://github.com/hyperopt/hyperopt-sklearn.git /tmp/pip-req-build-6iolv73c\n",
      "Requirement already satisfied (use --upgrade to upgrade): hpsklearn==0.0.3 from git+https://github.com/hyperopt/hyperopt-sklearn.git in /opt/conda/lib/python3.7/site-packages\n",
      "Requirement already satisfied: hyperopt in /opt/conda/lib/python3.7/site-packages (from hpsklearn==0.0.3) (0.2.5)\n",
      "Requirement already satisfied: nose in /opt/conda/lib/python3.7/site-packages (from hpsklearn==0.0.3) (1.3.7)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from hpsklearn==0.0.3) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from hpsklearn==0.0.3) (0.24.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from hpsklearn==0.0.3) (1.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from hyperopt->hpsklearn==0.0.3) (1.14.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from hyperopt->hpsklearn==0.0.3) (0.18.2)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from hyperopt->hpsklearn==0.0.3) (1.2.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from hyperopt->hpsklearn==0.0.3) (4.43.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from hyperopt->hpsklearn==0.0.3) (2.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->hpsklearn==0.0.3) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->hpsklearn==0.0.3) (0.14.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.2->hyperopt->hpsklearn==0.0.3) (4.4.1)\n",
      "Building wheels for collected packages: hpsklearn\n",
      "  Building wheel for hpsklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hpsklearn: filename=hpsklearn-0.0.3-py3-none-any.whl size=26922 sha256=160eb4a6db3e1ad826fe978195e55d396fcc03f541f26440cbaa5cb37e9fd4df\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-f694l91b/wheels/47/a5/46/9ca750026db9dfa5de4bf4836194554cb0e2e01a245588ea59\n",
      "Successfully built hpsklearn\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/hyperopt/hyperopt-sklearn.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2.2 - Use hyperopt estimator on best training data from group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try hyperopt estimator on a transformed smote dataset\n",
    "\n",
    "Charles has got the best model so far using standard scaler and smote to balance the classes. Try finding a new best base model with the same transformed data, and see if there is a better classifier out there thand logistic regression with liblinear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import load_data function from helper file \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# fix system path\n",
    "import sys\n",
    "sys.path.append(\"/home/jovyan/work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.helper_functions import load_sets\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test = load_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "from hpsklearn import HyperoptEstimator\n",
    "from hpsklearn import any_classifier\n",
    "from hpsklearn import any_preprocessing\n",
    "from hyperopt import tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07287296 -0.52299895 -0.6861803  ... -0.61178883 -0.33444528\n",
      "  -0.76943971]\n",
      " [ 1.06917581  0.25148433  0.08196862 ... -0.12153046 -0.33444528\n",
      "   0.05673496]\n",
      " [-0.74761174 -1.45462378 -1.36122026 ... -0.61178883 -0.48918032\n",
      "  -1.32022282]\n",
      " ...\n",
      " [-0.45458149 -0.33218423 -0.9189527  ... -0.36665964 -0.0249752\n",
      "  -0.63174393]\n",
      " [ 1.65523631  3.2932955   1.12944442 ...  0.61385711  0.43922991\n",
      "   0.4698223 ]\n",
      " [ 0.24869111  0.88005048  1.22255338 ... -0.12153046  3.22446059\n",
      "  -0.35635237]]\n",
      "[[-1.21646014 -1.25258466 -1.08189338 ... -0.85691802 -0.48918032\n",
      "  -1.32022282]\n",
      " [-0.22015729 -0.66891609 -1.0353389  ... -0.61178883 -0.17971024\n",
      "  -0.35635237]\n",
      " [ 0.42450926 -0.27606225  1.36221682 ... -0.61178883  0.12975984\n",
      "   0.19443074]\n",
      " ...\n",
      " [ 0.24869111  0.5882162   0.66389962 ...  1.10411549 -0.0249752\n",
      "   0.88290964]\n",
      " [-1.09924804  0.18413796  0.0121369  ...  0.12359873  0.12975984\n",
      "   0.05673496]\n",
      " [ 0.95196371  1.11576278  1.71137542 ...  1.34924467 -0.33444528\n",
      "   2.3975632 ]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_scale = scaler.fit_transform(X_train)\n",
    "\n",
    "X_val_scale = scaler.transform(X_val)\n",
    "\n",
    "print(X_scale)\n",
    "print(X_val_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dataset - will do automatic minority resampling\n",
    "oversample = SMOTE()\n",
    "X_smote, y_smote = oversample.fit_resample(X_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 5326, 0: 5326})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print('Resampled dataset shape %s' % Counter(y_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.18s/trial, best loss: 0.8488972313467855]\n",
      "100%|██████████| 2/2 [00:00<00:00, 18.00trial/s, best loss: 0.68700140778977]\n",
      "100%|██████████| 3/3 [00:00<00:00, 11.82trial/s, best loss: 0.29516658845612387]\n",
      "100%|██████████| 4/4 [00:04<00:00,  1.10s/trial, best loss: 0.29516658845612387]\n",
      "100%|██████████| 5/5 [00:30<00:00,  6.02s/trial, best loss: 0.29516658845612387]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.77s/trial, best loss: 0.09713749413420925]\n",
      "100%|██████████| 7/7 [00:08<00:00,  1.23s/trial, best loss: 0.09713749413420925]\n",
      "100%|██████████| 8/8 [00:00<00:00, 17.24trial/s, best loss: 0.09713749413420925]\n",
      "100%|██████████| 9/9 [00:03<00:00,  2.91trial/s, best loss: 0.09713749413420925]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.22trial/s, best loss: 0.09713749413420925]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.16trial/s, best loss: 0.09713749413420925]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.40trial/s, best loss: 0.09713749413420925]\n",
      "100%|██████████| 13/13 [00:01<00:00,  9.44trial/s, best loss: 0.07038948850305016]\n",
      "100%|██████████| 14/14 [00:04<00:00,  2.97trial/s, best loss: 0.07038948850305016]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.46trial/s, best loss: 0.07038948850305016]\n",
      "100%|██████████| 16/16 [00:02<00:00,  7.12trial/s, best loss: 0.07038948850305016]\n",
      " 94%|█████████▍| 16/17 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:26:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 17/17 [00:30<00:00,  1.77s/trial, best loss: 0.07038948850305016]\n",
      "100%|██████████| 18/18 [00:30<00:00,  1.67s/trial, best loss: 0.07038948850305016]\n",
      " 95%|█████████▍| 18/19 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:27:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 19/19 [00:30<00:00,  1.59s/trial, best loss: 0.07038948850305016]\n",
      "100%|██████████| 20/20 [00:05<00:00,  3.72trial/s, best loss: 0.07038948850305016]\n",
      "100%|██████████| 21/21 [00:17<00:00,  1.23trial/s, best loss: 0.07038948850305016]\n",
      "100%|██████████| 22/22 [00:00<00:00, 60.01trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 23/23 [00:00<00:00, 77.26trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 24/24 [00:00<00:00, 78.59trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 25/25 [00:00<00:00, 67.79trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 26/26 [00:00<00:00, 73.98trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 27/27 [00:00<00:00, 56.99trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 28/28 [00:00<00:00, 45.91trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 29/29 [00:00<00:00, 169.87trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 30/30 [00:22<00:00,  1.33trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 31/31 [00:00<00:00, 76.21trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 32/32 [00:00<00:00, 58.49trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 33/33 [00:00<00:00, 200.00trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 34/34 [00:00<00:00, 177.19trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 35/35 [00:00<00:00, 105.19trial/s, best loss: 0.002815579540122015]\n",
      " 97%|█████████▋| 35/36 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:28:58] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 36/36 [00:00<00:00, 59.62trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 37/37 [00:01<00:00, 24.05trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 38/38 [00:00<00:00, 93.36trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 39/39 [00:00<00:00, 128.24trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 40/40 [00:00<00:00, 247.88trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 41/41 [00:30<00:00,  1.36trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 42/42 [00:00<00:00, 155.80trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 43/43 [00:00<00:00, 102.60trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 44/44 [00:00<00:00, 84.39trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 45/45 [00:02<00:00, 20.79trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 46/46 [00:00<00:00, 93.78trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 47/47 [00:00<00:00, 116.15trial/s, best loss: 0.002815579540122015]\n",
      " 98%|█████████▊| 47/48 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:29:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 48/48 [00:01<00:00, 26.63trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 49/49 [00:09<00:00,  5.30trial/s, best loss: 0.002815579540122015]\n",
      "100%|██████████| 50/50 [00:00<00:00, 122.50trial/s, best loss: 0.002815579540122015]\n",
      "Accuracy: 0.664\n",
      "{'learner': KNeighborsClassifier(metric='euclidean', n_jobs=1, n_neighbors=1,\n",
      "                     weights='distance'), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    }
   ],
   "source": [
    "# define search\n",
    "model = HyperoptEstimator(classifier=any_classifier('cla'), preprocessing = [], algo=tpe.suggest, max_evals=50, trial_timeout=30, seed = 42)\n",
    "# pass an empty list to preprocessing to do nothing\n",
    "\n",
    "# perform the search\n",
    "model.fit(X_smote, y_smote)\n",
    "\n",
    "# summarize performance\n",
    "acc = model.score(X_val_scale, y_val) \n",
    "# hyperopt estimator only does accuracy or R2 scores https://github.com/hyperopt/hyperopt-sklearn/blob/fd718c44fc440bd6e2718ec1442b1af58cafcb18/hpsklearn/estimator.py#L844\n",
    "print(\"Accuracy: %.3f\" % acc)\n",
    "# summarize the best model\n",
    "print(model.best_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train this model again using the above model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(metric='euclidean', n_jobs=1, n_neighbors=1,\n",
    "                     weights='distance')\n",
    "\n",
    "knc = model.fit(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved succesfully\n"
     ]
    }
   ],
   "source": [
    "from src.features.helper_functions import save_model\n",
    "save_model(knc, 'knclf_scale_smote_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new upsampled data to interim\n",
    "np.save('../data/interim/X_train_scale_smote', X_smote)\n",
    "np.save('../data/interim/y_train_scale_smote', y_smote)\n",
    "np.save('../data/interim/X_val_scale', X_val_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model_smote = GradientBoostingClassifier(learning_rate=0.3200712536391533, max_depth=4,\n",
    "#                            n_estimators=967, random_state=1,\n",
    "#                            subsample=0.5066639200300195)\n",
    "\n",
    "# gbc = model_smote.fit(X_smote_scale, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict class\n",
    "y_train_preds = knc.predict(X_smote)\n",
    "y_val_preds = knc.predict(X_val_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict proabilities\n",
    "y_train_preds_prob = knc.predict_proba(X_smote)\n",
    "y_val_preds_prob = knc.predict_proba(X_val_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.helper_functions import result_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "Precision: 100.00% \n",
      "Recall: 100.00% \n",
      "AUC using prediction probabilities: 100.000% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5326\n",
      "           1       1.00      1.00      1.00      5326\n",
      "\n",
      "    accuracy                           1.00     10652\n",
      "   macro avg       1.00      1.00      1.00     10652\n",
      "weighted avg       1.00      1.00      1.00     10652\n",
      "\n",
      "Confusion Matrix\n",
      "[[5326    0]\n",
      " [   0 5326]]\n"
     ]
    }
   ],
   "source": [
    "result_metrics(y_smote, y_train_preds,y_train_preds_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.25%\n",
      "Precision: 84.69% \n",
      "Recall: 91.88% \n",
      "AUC using prediction probabilities: 58.319% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.13      0.17       257\n",
      "           1       0.85      0.92      0.88      1343\n",
      "\n",
      "    accuracy                           0.79      1600\n",
      "   macro avg       0.54      0.53      0.53      1600\n",
      "weighted avg       0.75      0.79      0.77      1600\n",
      "\n",
      "Confusion Matrix\n",
      "[[  34  223]\n",
      " [ 109 1234]]\n"
     ]
    }
   ],
   "source": [
    "result_metrics(y_val, y_val_preds,y_val_preds_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "from src.features.helper_functions import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved succesfully\n"
     ]
    }
   ],
   "source": [
    "save_model(etclf, 'rez_etclf_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an output for kaggle testing anyway.\n",
    "y_test_preds = etclf.predict(X_test)\n",
    "y_test_preds_prob = etclf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 1 0]\n",
      "[[0.55198684 0.44801316]\n",
      " [0.50364994 0.49635006]\n",
      " [0.3517363  0.6482637 ]\n",
      " ...\n",
      " [0.58697257 0.41302743]\n",
      " [0.32636914 0.67363086]\n",
      " [0.55008323 0.44991677]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_preds)\n",
    "print(y_test_preds_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1]\n",
      " [1619 2180]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(y_test_preds, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7426605504587156"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1619/2180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.helper_functions import create_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = create_output(y_test_preds_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.448013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.496350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.648264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.689108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.442623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>3794</td>\n",
       "      <td>0.623098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>3795</td>\n",
       "      <td>0.524807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>3796</td>\n",
       "      <td>0.413027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>3797</td>\n",
       "      <td>0.673631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>3798</td>\n",
       "      <td>0.449917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3799 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  TARGET_5Yrs\n",
       "0        0     0.448013\n",
       "1        1     0.496350\n",
       "2        2     0.648264\n",
       "3        3     0.689108\n",
       "4        4     0.442623\n",
       "...    ...          ...\n",
       "3794  3794     0.623098\n",
       "3795  3795     0.524807\n",
       "3796  3796     0.413027\n",
       "3797  3797     0.673631\n",
       "3798  3798     0.449917\n",
       "\n",
       "[3799 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
