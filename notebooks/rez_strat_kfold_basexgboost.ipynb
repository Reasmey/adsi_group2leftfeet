{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1.1 - Xgboost with k-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base xgboost model using default settings provided a reasonable AUC of 0.64.\n",
    "\n",
    "To try and improve the score without having to change any settings, lets try k-fold cross validation. This should see improved generalisability on our imbalanced dataset with the use of stratified k-fold to keep the ratio of classes in each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import load_data function from helper file \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# fix system path\n",
    "import sys\n",
    "sys.path.append(\"/home/jovyan/work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.helper_functions import load_sets\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test = load_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.416e+03  6.400e+01  1.390e+01 ...  4.000e-01  1.000e-01  7.000e-01]\n",
      " [ 4.919e+03  8.100e+01  2.080e+01 ...  6.000e-01  1.000e-01  1.300e+00]\n",
      " [ 7.672e+03  5.000e+01  5.600e+00 ...  4.000e-01 -3.000e-01  3.000e-01]\n",
      " ...\n",
      " [ 5.832e+03  5.500e+01  1.560e+01 ...  5.000e-01  3.000e-01  8.000e-01]\n",
      " [ 5.163e+03  9.100e+01  4.790e+01 ...  9.000e-01  6.000e-01  1.600e+00]\n",
      " [ 8.346e+03  6.700e+01  2.640e+01 ...  6.000e-01  2.400e+00  1.000e+00]]\n",
      "[[0.000e+00 5.600e+01 9.100e+00 ... 2.000e-01 3.000e-01 8.000e-01]\n",
      " [1.000e+00 4.300e+01 1.930e+01 ... 6.000e-01 0.000e+00 1.800e+00]\n",
      " [2.000e+00 8.200e+01 3.390e+01 ... 1.300e+00 3.000e-01 2.000e+00]\n",
      " ...\n",
      " [3.796e+03 5.300e+01 9.900e+00 ... 4.000e-01 2.000e-01 5.000e-01]\n",
      " [3.797e+03 8.900e+01 3.830e+01 ... 1.300e+00 3.000e-01 2.400e+00]\n",
      " [3.798e+03 5.500e+01 1.200e+01 ... 3.000e-01 2.000e-01 1.200e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold settings\n",
    "Example taken from here https://machinelearningmastery.com/evaluate-gradient-boosting-models-xgboost-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# choose number of splits, set shuffle to true and random state=8 to ensure reproducible output\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle = True, random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "Follow the same process as base model, this time using kfolds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.3.3-py3-none-manylinux2010_x86_64.whl (157.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 157.5 MB 14 kB/s  eta 0:00:011  |█▏                              | 5.7 MB 2.7 MB/s eta 0:00:58     |█▎                              | 6.1 MB 2.7 MB/s eta 0:00:57     |█▋                              | 7.9 MB 11.3 MB/s eta 0:00:14     |███                             | 15.1 MB 6.5 MB/s eta 0:00:22     |████▍                           | 21.7 MB 6.6 MB/s eta 0:00:21     |████▌                           | 22.1 MB 6.6 MB/s eta 0:00:21     |████▉                           | 23.8 MB 6.6 MB/s eta 0:00:21     |█████▏                          | 25.2 MB 6.6 MB/s eta 0:00:21     |█████▋                          | 27.7 MB 5.8 MB/s eta 0:00:23     |██████▊                         | 33.3 MB 5.8 MB/s eta 0:00:22     |███████▏                        | 35.0 MB 5.9 MB/s eta 0:00:21     |███████▏                        | 35.4 MB 5.9 MB/s eta 0:00:21     |███████▎                        | 35.7 MB 5.9 MB/s eta 0:00:21     |███████▌                        | 37.1 MB 5.9 MB/s eta 0:00:21     |███████▋                        | 37.5 MB 5.9 MB/s eta 0:00:21     |████████                        | 38.9 MB 5.9 MB/s eta 0:00:21     |████████▎                       | 40.6 MB 4.8 MB/s eta 0:00:25     |████████▌                       | 42.0 MB 4.8 MB/s eta 0:00:25     |████████▊                       | 42.7 MB 4.8 MB/s eta 0:00:24     |████████▉                       | 43.4 MB 4.8 MB/s eta 0:00:24     |█████████▋                      | 47.6 MB 7.0 MB/s eta 0:00:16     |██████████▏                     | 50.0 MB 7.0 MB/s eta 0:00:16     |██████████▊                     | 52.8 MB 7.0 MB/s eta 0:00:15     |███████████                     | 53.8 MB 7.0 MB/s eta 0:00:15     |███████████                     | 54.1 MB 7.0 MB/s eta 0:00:15     |███████████                     | 54.5 MB 5.5 MB/s eta 0:00:19     |███████████▏                    | 54.8 MB 5.5 MB/s eta 0:00:19     |███████████▎                    | 55.6 MB 5.5 MB/s eta 0:00:19     |███████████▍                    | 56.2 MB 5.5 MB/s eta 0:00:19     |███████████████                 | 73.7 MB 6.1 MB/s eta 0:00:14     |███████████████▎                | 75.4 MB 7.3 MB/s eta 0:00:12�██████████▋                | 76.9 MB 7.3 MB/s eta 0:00:12     |████████████████                | 79.2 MB 7.3 MB/s eta 0:00:11     |████████████████▏               | 79.5 MB 7.3 MB/s eta 0:00:11     |████████████████▌               | 81.3 MB 7.3 MB/s eta 0:00:11     |████████████████▊               | 82.3 MB 6.9 MB/s eta 0:00:11     |█████████████████▏              | 84.5 MB 6.9 MB/s eta 0:00:11     |█████████████████▎              | 84.8 MB 6.9 MB/s eta 0:00:11     |█████████████████▋              | 86.5 MB 6.9 MB/s eta 0:00:11     |██████████████████              | 89.0 MB 6.9 MB/s eta 0:00:10     |██████████████████▍             | 90.3 MB 6.9 MB/s eta 0:00:10     |██████████████████▍             | 90.6 MB 6.9 MB/s eta 0:00:10     |██████████████████▊             | 92.4 MB 6.9 MB/s eta 0:00:10     |███████████████████             | 93.9 MB 6.9 MB/s eta 0:00:10     |███████████████████▏            | 94.2 MB 6.9 MB/s eta 0:00:10     |██████████████████████▎         | 109.7 MB 5.2 MB/s eta 0:00:10     |██████████████████████▊         | 111.7 MB 7.6 MB/s eta 0:00:07     |████████████████████████▏       | 119.0 MB 5.9 MB/s eta 0:00:07     |████████████████████████▌       | 120.4 MB 5.9 MB/s eta 0:00:07     |████████████████████████▊       | 121.5 MB 5.9 MB/s eta 0:00:07     |████████████████████████▊       | 121.8 MB 5.9 MB/s eta 0:00:07     |█████████████████████████▌      | 125.3 MB 5.6 MB/s eta 0:00:06     |█████████████████████████▌      | 125.7 MB 5.6 MB/s eta 0:00:06     |███████████████████████████     | 132.4 MB 6.6 MB/s eta 0:00:04     |███████████████████████████▍    | 134.6 MB 6.6 MB/s eta 0:00:04     |███████████████████████████▍    | 134.9 MB 6.6 MB/s eta 0:00:04     |███████████████████████████▊    | 136.5 MB 6.6 MB/s eta 0:00:04     |█████████████████████████████▎  | 144.1 MB 5.7 MB/s eta 0:00:03     |█████████████████████████████▍  | 144.4 MB 6.2 MB/s eta 0:00:03     |█████████████████████████████▋  | 145.8 MB 6.2 MB/s eta 0:00:02     |██████████████████████████████▋ | 150.5 MB 6.2 MB/s eta 0:00:02     |███████████████████████████████ | 152.6 MB 10.1 MB/s eta 0:00:01     |███████████████████████████████ | 152.9 MB 10.1 MB/s eta 0:00:01     |███████████████████████████████▍| 154.5 MB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.18.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# won't recognise pipfile, need to revisit this at some point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiate model\n",
    "model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:56:35] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:56:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:56:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:56:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:56:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:56:38] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:56:38] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:56:39] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:56:39] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:56:40] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 81.81% (0.50%)\n"
     ]
    }
   ],
   "source": [
    "# fit on train set using sklearns cross val score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy using validation set in base model was slightly higher at 82%\n",
    "\n",
    "need to perform the same thing on all training data, and with different kfolds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8125   , 0.8140625, 0.81875  , 0.8234375, 0.8203125, 0.8109375,\n",
       "       0.81875  , 0.828125 , 0.8140625, 0.8203125])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset - train\n",
    "training_data = pd.read_csv('../data/raw/train (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = training_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove id_old\n",
    "df_cleaned.drop('Id_old', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 21)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Y\n",
    "target = df_cleaned.pop('TARGET_5Yrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:14:57] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:14:57] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:14:58] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:14:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:14:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:15:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:15:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:15:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:15:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:15:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 82.23% (0.49%)\n"
     ]
    }
   ],
   "source": [
    "# use all training data with 10 kfolds\n",
    "results_10 = cross_val_score(model, df_cleaned, target, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results_10.mean()*100, results_10.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:16:16] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:16:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:16:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:16:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:16:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 81.92% (0.23%)\n"
     ]
    }
   ],
   "source": [
    "# use less kfolds\n",
    "kfold5 = StratifiedKFold(n_splits=5, shuffle = True, random_state=8)\n",
    "\n",
    "results_10 = cross_val_score(model, df_cleaned, target, cv=kfold5)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results_10.mean()*100, results_10.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:17:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:04] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:04] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:06] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:06] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:07] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:09] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:09] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:10] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:11] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:11] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:12] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:12] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:13] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:17:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 81.91% (1.05%)\n"
     ]
    }
   ],
   "source": [
    "# use more kfolds\n",
    "kfold20 = StratifiedKFold(n_splits=20, shuffle = True, random_state=8)\n",
    "\n",
    "results_20 = cross_val_score(model, df_cleaned, target, cv=kfold20)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results_20.mean()*100, results_20.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verdict\n",
    "\n",
    "Using kfold cross validation did not improve the accuracy of the results by any significant amount. \n",
    "\n",
    "Even thought the classes are imbalanced, the use of random smaller samples doesn't seem to make a difference.\n",
    "\n",
    "Can keep using train/val split to evaluate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
