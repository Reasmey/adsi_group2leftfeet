{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2.1 - Hyperopt to find best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/hyperopt/hyperopt-sklearn.git\n",
      "  Cloning https://github.com/hyperopt/hyperopt-sklearn.git to /tmp/pip-req-build-ezpywh0s\n",
      "  Running command git clone -q https://github.com/hyperopt/hyperopt-sklearn.git /tmp/pip-req-build-ezpywh0s\n",
      "Requirement already satisfied (use --upgrade to upgrade): hpsklearn==0.0.3 from git+https://github.com/hyperopt/hyperopt-sklearn.git in /opt/conda/lib/python3.7/site-packages\n",
      "Requirement already satisfied: hyperopt in /opt/conda/lib/python3.7/site-packages (from hpsklearn==0.0.3) (0.2.5)\n",
      "Requirement already satisfied: nose in /opt/conda/lib/python3.7/site-packages (from hpsklearn==0.0.3) (1.3.7)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from hpsklearn==0.0.3) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from hpsklearn==0.0.3) (0.24.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from hpsklearn==0.0.3) (1.4.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from hyperopt->hpsklearn==0.0.3) (2.4)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from hyperopt->hpsklearn==0.0.3) (0.18.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from hyperopt->hpsklearn==0.0.3) (4.43.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from hyperopt->hpsklearn==0.0.3) (1.14.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from hyperopt->hpsklearn==0.0.3) (1.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->hpsklearn==0.0.3) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->hpsklearn==0.0.3) (0.14.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.2->hyperopt->hpsklearn==0.0.3) (4.4.1)\n",
      "Building wheels for collected packages: hpsklearn\n",
      "  Building wheel for hpsklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hpsklearn: filename=hpsklearn-0.0.3-py3-none-any.whl size=26922 sha256=b7067fea2957c9afd6ebb652739dcd2b047d40a09822a80cc53490c6e01b4c8f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_mgnnuyb/wheels/47/a5/46/9ca750026db9dfa5de4bf4836194554cb0e2e01a245588ea59\n",
      "Successfully built hpsklearn\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/hyperopt/hyperopt-sklearn.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import load_data function from helper file \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# fix system path\n",
    "import sys\n",
    "sys.path.append(\"/home/jovyan/work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.helper_functions import load_sets\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test = load_sets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/hyperopt-for-automated-machine-learning-with-scikit-learn/\n",
    "\n",
    "https://github.com/hyperopt/hyperopt-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "from hpsklearn import HyperoptEstimator\n",
    "from hpsklearn import any_classifier\n",
    "from hpsklearn import any_preprocessing\n",
    "from hyperopt import tpe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.47s/trial, best loss: 0.17578125]\n",
      "100%|██████████| 2/2 [00:00<00:00, 23.23trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 3/3 [00:00<00:00, 15.38trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.70trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 5/5 [00:30<00:00,  6.01s/trial, best loss: 0.17578125]\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.11trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 7/7 [00:04<00:00,  1.67trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 8/8 [00:00<00:00, 15.03trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 9/9 [00:00<00:00, 11.84trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.13trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 11/11 [00:02<00:00,  4.47trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 12/12 [00:00<00:00, 17.17trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 13/13 [00:00<00:00, 16.38trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 14/14 [00:00<00:00, 25.21trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 15/15 [00:00<00:00, 19.35trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 16/16 [00:00<00:00, 39.48trial/s, best loss: 0.17578125]\n",
      " 94%|█████████▍| 16/17 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:19:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 17/17 [00:21<00:00,  1.28s/trial, best loss: 0.17578125]\n",
      "100%|██████████| 18/18 [00:30<00:00,  1.67s/trial, best loss: 0.17578125]\n",
      " 95%|█████████▍| 18/19 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:19:53] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 19/19 [00:21<00:00,  1.13s/trial, best loss: 0.17578125]\n",
      "100%|██████████| 20/20 [00:01<00:00, 10.62trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 21/21 [00:00<00:00, 50.98trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 22/22 [00:00<00:00, 62.43trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 23/23 [00:04<00:00,  4.73trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 24/24 [00:09<00:00,  2.52trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 25/25 [00:00<00:00, 77.73trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 26/26 [00:05<00:00,  4.81trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 27/27 [00:09<00:00,  2.85trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 28/28 [00:08<00:00,  3.17trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 29/29 [00:01<00:00, 19.08trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 30/30 [00:01<00:00, 22.30trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 31/31 [00:03<00:00,  8.96trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 32/32 [00:01<00:00, 31.96trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 33/33 [00:01<00:00, 25.26trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 34/34 [00:00<00:00, 136.24trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 35/35 [00:00<00:00, 137.80trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 36/36 [00:00<00:00, 59.37trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 37/37 [00:00<00:00, 174.75trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 38/38 [00:00<00:00, 148.85trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 39/39 [00:00<00:00, 149.05trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 40/40 [00:00<00:00, 230.12trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 41/41 [00:00<00:00, 161.92trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 42/42 [00:00<00:00, 122.99trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 43/43 [00:00<00:00, 46.93trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 44/44 [00:09<00:00,  4.57trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 45/45 [00:00<00:00, 238.36trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 46/46 [00:00<00:00, 229.18trial/s, best loss: 0.17578125]\n",
      " 98%|█████████▊| 46/47 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:21:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 47/47 [00:00<00:00, 99.87trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 48/48 [00:05<00:00,  9.36trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 49/49 [00:09<00:00,  5.37trial/s, best loss: 0.17578125]\n",
      "100%|██████████| 50/50 [00:00<00:00, 208.22trial/s, best loss: 0.17578125]\n",
      "Accuracy: 0.839\n",
      "{'learner': ExtraTreesClassifier(bootstrap=True, max_depth=2,\n",
      "                     max_features=0.5114013866515924, n_estimators=1145,\n",
      "                     n_jobs=1, random_state=1, verbose=False), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define search\n",
    "model = HyperoptEstimator(classifier=any_classifier('cla'), preprocessing = [], algo=tpe.suggest, max_evals=50, trial_timeout=30, seed = 42)\n",
    "# pass an empty list to preprocessing to do nothing\n",
    "\n",
    "# perform the search\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# summarize performance\n",
    "acc = model.score(X_val, y_val)\n",
    "print(\"Accuracy: %.3f\" % acc)\n",
    "# summarize the best model\n",
    "print(model.best_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train this model again using the above model\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "model = ExtraTreesClassifier(bootstrap=True, max_depth=2, class_weight = \"balanced_subsample\",\n",
    "                     max_features=0.5114013866515924, n_estimators=1145,\n",
    "                     n_jobs=1, random_state=1, verbose=False)\n",
    "\n",
    "etclf = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict class\n",
    "y_train_preds = etclf.predict(X_train)\n",
    "y_val_preds = etclf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict proabilities\n",
    "y_train_preds_prob = etclf.predict_proba(X_train)\n",
    "y_val_preds_prob = etclf.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.helper_functions import result_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.41%\n",
      "Precision: 89.98% \n",
      "Recall: 61.70% \n",
      "AUC using prediction probabilities: 68.970% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.66      0.37      1074\n",
      "           1       0.90      0.62      0.73      5326\n",
      "\n",
      "    accuracy                           0.62      6400\n",
      "   macro avg       0.58      0.64      0.55      6400\n",
      "weighted avg       0.79      0.62      0.67      6400\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 708  366]\n",
      " [2040 3286]]\n"
     ]
    }
   ],
   "source": [
    "result_metrics(y_train, y_train_preds,y_train_preds_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.50%\n",
      "Precision: 90.78% \n",
      "Recall: 61.58% \n",
      "AUC using prediction probabilities: 69.769% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.67      0.37       257\n",
      "           1       0.91      0.62      0.73      1343\n",
      "\n",
      "    accuracy                           0.62      1600\n",
      "   macro avg       0.58      0.64      0.55      1600\n",
      "weighted avg       0.80      0.62      0.67      1600\n",
      "\n",
      "Confusion Matrix\n",
      "[[173  84]\n",
      " [516 827]]\n"
     ]
    }
   ],
   "source": [
    "result_metrics(y_val, y_val_preds,y_val_preds_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "from src.features.helper_functions import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved succesfully\n"
     ]
    }
   ],
   "source": [
    "save_model(etclf, 'rez_etclf_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an output for kaggle testing anyway.\n",
    "y_test_preds = etclf.predict(X_test)\n",
    "y_test_preds_prob = etclf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 1 0]\n",
      "[[0.55198684 0.44801316]\n",
      " [0.50364994 0.49635006]\n",
      " [0.3517363  0.6482637 ]\n",
      " ...\n",
      " [0.58697257 0.41302743]\n",
      " [0.32636914 0.67363086]\n",
      " [0.55008323 0.44991677]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_preds)\n",
    "print(y_test_preds_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1]\n",
      " [1619 2180]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(y_test_preds, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7426605504587156"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1619/2180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.helper_functions import create_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = create_output(y_test_preds_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.448013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.496350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.648264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.689108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.442623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>3794</td>\n",
       "      <td>0.623098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>3795</td>\n",
       "      <td>0.524807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>3796</td>\n",
       "      <td>0.413027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>3797</td>\n",
       "      <td>0.673631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>3798</td>\n",
       "      <td>0.449917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3799 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  TARGET_5Yrs\n",
       "0        0     0.448013\n",
       "1        1     0.496350\n",
       "2        2     0.648264\n",
       "3        3     0.689108\n",
       "4        4     0.442623\n",
       "...    ...          ...\n",
       "3794  3794     0.623098\n",
       "3795  3795     0.524807\n",
       "3796  3796     0.413027\n",
       "3797  3797     0.673631\n",
       "3798  3798     0.449917\n",
       "\n",
       "[3799 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "output.to_csv('../data/processed/output_etclf_wk3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KAGGLE 0.69803"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try using the extra trees classifier as a base to adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base model\n",
    "base = model # from above\n",
    "# define ensemble model\n",
    "adaboost = AdaBoostClassifier(base_estimator=base,n_estimators = 150, learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# evaluate the model and collect the results\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73965037, 0.68243587, 0.69465729, 0.67186267, 0.6599218 ,\n",
       "       0.6989006 , 0.70962128, 0.68025968, 0.66424742, 0.6472083 ,\n",
       "       0.66221879, 0.69718223, 0.71924041, 0.65795795, 0.67451035,\n",
       "       0.63696937, 0.70112782, 0.72606864, 0.68736076, 0.67898914,\n",
       "       0.69143098, 0.68643369, 0.67321281, 0.756834  , 0.71301573,\n",
       "       0.66628676, 0.6810951 , 0.6769702 , 0.66551796, 0.63077833])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.684398877235343"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use it - see what happens\n",
    "etclf_adaboost = adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict class\n",
    "y_train_preds = etclf_adaboost.predict(X_train)\n",
    "y_val_preds = etclf_adaboost.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict proabilities\n",
    "y_train_preds_prob = etclf_adaboost.predict_proba(X_train)\n",
    "y_val_preds_prob = etclf_adaboost.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.08%\n",
      "Precision: 90.92% \n",
      "Recall: 64.48% \n",
      "AUC using prediction probabilities: 72.650% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.68      0.40      1074\n",
      "           1       0.91      0.64      0.75      5326\n",
      "\n",
      "    accuracy                           0.65      6400\n",
      "   macro avg       0.59      0.66      0.57      6400\n",
      "weighted avg       0.80      0.65      0.69      6400\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 731  343]\n",
      " [1892 3434]]\n"
     ]
    }
   ],
   "source": [
    "result_metrics(y_train, y_train_preds,y_train_preds_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.06%\n",
      "Precision: 90.34% \n",
      "Recall: 64.04% \n",
      "AUC using prediction probabilities: 70.570% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.64      0.36       257\n",
      "           1       0.90      0.64      0.75      1343\n",
      "\n",
      "    accuracy                           0.64      1600\n",
      "   macro avg       0.58      0.64      0.56      1600\n",
      "weighted avg       0.80      0.64      0.69      1600\n",
      "\n",
      "Confusion Matrix\n",
      "[[165  92]\n",
      " [483 860]]\n"
     ]
    }
   ],
   "source": [
    "result_metrics(y_val, y_val_preds,y_val_preds_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved succesfully\n"
     ]
    }
   ],
   "source": [
    "save_model(etclf, 'rez_etclf_adaboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an output for kaggle testing anyway.\n",
    "y_test_preds = etclf_adaboost.predict(X_test)\n",
    "y_test_preds_prob = etclf_adaboost.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 1 0]\n",
      "[[0.50389802 0.49610198]\n",
      " [0.50422836 0.49577164]\n",
      " [0.48052584 0.51947416]\n",
      " ...\n",
      " [0.50795938 0.49204062]\n",
      " [0.479326   0.520674  ]\n",
      " [0.50453972 0.49546028]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_preds)\n",
    "print(y_test_preds_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1]\n",
      " [1560 2239]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(y_test_preds, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6967396158999554"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1560/2239"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.helper_functions import create_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = create_output(y_test_preds_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.496102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.495772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.519474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.542378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.494874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>3794</td>\n",
       "      <td>0.520148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>3795</td>\n",
       "      <td>0.500218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>3796</td>\n",
       "      <td>0.492041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>3797</td>\n",
       "      <td>0.520674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>3798</td>\n",
       "      <td>0.495460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3799 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  TARGET_5Yrs\n",
       "0        0     0.496102\n",
       "1        1     0.495772\n",
       "2        2     0.519474\n",
       "3        3     0.542378\n",
       "4        4     0.494874\n",
       "...    ...          ...\n",
       "3794  3794     0.520148\n",
       "3795  3795     0.500218\n",
       "3796  3796     0.492041\n",
       "3797  3797     0.520674\n",
       "3798  3798     0.495460\n",
       "\n",
       "[3799 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "output.to_csv('../data/processed/output_etclf_adaboost_wk3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KAGGLE 0.70974"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
